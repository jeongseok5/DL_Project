# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10qEtu_1na5AEX-xqxPo_dBK4n-LUFaax
"""

import os
import torch
import torch.nn as nn
import sys
from PIL import Image
from glob import glob
import torchvision.transforms as transforms
from torchvision import datasets, models
from torch.utils.data import DataLoader

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

model = models.resnet101(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 3)

model.load_state_dict(torch.load("/content/parameter.pt"))

model.to(device)
if torch.cuda.is_available():
    model.cuda()

### Custom Dataset
class RSPDataset(torch.utils.data.Dataset):
  def __init__(self, path):
    self.test_files = glob(path+"/*")
    self.images = self.test_files
    # transforms.Compose
    transform = {
    'train': transforms.Compose([
                                transforms.RandomResizedCrop(224),
                                transforms.RandomHorizontalFlip(),
                                transforms.ToTensor(),
                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                               ]),
    'val': transforms.Compose([
                               transforms.CenterCrop(224),
                               transforms.ToTensor(),
                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                               ]),
    'test': transforms.Compose([
                               transforms.Resize((224,224)),
                               transforms.ToTensor(),
                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                               ])
    }
    self.totensor = transform['test'] # test용


  def __len__(self):
    return len(self.images)

  def __getitem__(self, idx):
    images = Image.open(self.images[idx]).convert('RGB')
    return self.totensor(images)

# Method for returning filename
  def filename(self, idx):
    img_path = self.images[idx]
    filename = img_path.split('/')[-1].split('.')[0]
    return filename

# load test data
test_dir = str(sys.argv[1])

# test_dir = os.path.join("/content/drive/MyDrive/test")
batch_size=32
custom_dataset = RSPDataset(test_dir)
test_data_loader = torch.utils.data.DataLoader(
    custom_dataset, batch_size=batch_size, shuffle=False, num_workers=2)



save_dir = test_dir
f = open(os.path.join("/content", "output.txt"), 'w')


with torch.no_grad():

    for inputs in test_data_loader:
      inputs = inputs.to(device)

      output = model.forward(inputs)
      _, output_index = torch.max(output, 1) #최대값과 최대값 인덱스를 뽑아냄
        
      for i in range(len(output_index)): # batch를 도는 iterator
        predict = output_index[i] # 이미지 한장의 predict

        # filename
        filename = custom_dataset.filename(i)
        if predict == 0: # 바위로 predict
          result = filename+"\t2\n"
          f.write(result)
        elif predict ==1: # 가위로 predict
          result = filename+"\t0\n"
          f.write(result)
        else:             # 보로 predict
          result = filename+"\t1\n"
          f.write(result)


f.close()
print("/content에","output.txt 저장 완료!")

